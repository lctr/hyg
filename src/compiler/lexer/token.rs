use crate::{
    prelude::{
        either::Either,
        symbol::{Lexicon, Symbol},
    },
    strenum,
};

use super::Location;

strenum! { Keyword is_kw ::
    Do      "do"
    Let     "let"
    In      "in"
    If      "if"
    Then    "then"
    Else    "else"
    Case    "case"
    Of      "of"
    Where   "where"
    Data    "data"
    Class   "class"
    Fn      "fn"
    Import  "import"
    Export  "export"
    InfixL  "infixl"
    InfixR  "infixr"
    Derive  "deriving"

}

strenum! { NumFlag is_num_flag ::
    Bin "b"
    Oct "o"
    Hex "x"
    Dec "."
    Sci "e"
    Int ""
}

impl Default for NumFlag {
    fn default() -> Self {
        Self::Int
    }
}

#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]
pub enum Assoc {
    Left,
    Right,
    // Undecided on keeping this
    #[allow(unused)]
    None,
}

impl From<Either<(), ()>> for Assoc {
    fn from(either: Either<(), ()>) -> Self {
        if either.is_left() {
            Self::Left
        } else {
            Self::Right
        }
    }
}

impl Assoc {
    /// Utility matching functions as for brevity when using in parser
    #[inline]
    pub fn is_left(&self) -> bool {
        matches!(self, Self::Left)
    }

    #[inline]
    pub fn is_right(&self) -> bool {
        matches!(self, Self::Right)
    }

    #[inline]
    pub fn is_none(&self) -> bool {
        matches!(self, Self::None)
    }
}

strenum! { each BinOp is_binary ::
    // TODO!
    // forward composition
    // a -> (a -> b) -> b
    PipeR     "|>"   @ 1 L
    // backward composition
    // (a -> b) -> a -> b
    PipeL     "<|"   @ 0 R
    Or        "||"   @ 2 L
    And       "&&"   @ 3 L
    NotEq     "!="
    Equal     "=="
    Less      "<"
    LessEq    "<="
    Greater   ">"
    GreaterEq "=>"   @ 5 L
    Plus      "+"
    Link      "<>"   @ 6 L
    Minus     "-"    @ 7 L
    Times     "*"
    Div       "/"
    Rem       "%"
    Mod       "mod"  @ 8 L
    Pow       "**"
    Raise     "^"    @ 9 R
    //
    CompL     "</"   @ 10 R
    CompR     "\\>"  @ 10 L
    //
}

#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]
pub enum Operator {
    Reserved(BinOp),
    Custom(Symbol),
}

impl Operator {
    #![allow(unused)]
    pub const MIN_PREC: u8 = 1;
    pub const MAX_PREC: u8 = 10;
}

impl From<BinOp> for Operator {
    fn from(op: BinOp) -> Self {
        Operator::Reserved(op)
    }
}

impl std::fmt::Display for Operator {
    fn fmt(
        &self,
        f: &mut std::fmt::Formatter<'_>,
    ) -> std::fmt::Result {
        match self {
            Operator::Reserved(x) => write!(f, "{}", x),
            Operator::Custom(x) => write!(f, "{}", x),
        }
    }
}

#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub enum Comment {
    Line(String),
    Block(String),
    // TODO:
    // Doc(String),
}

#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub enum Token {
    Kw(Keyword),
    Operator(Operator),
    Comment(Comment),
    // Identifiers
    Lower(Symbol),
    // Types, constructors
    Upper(Symbol),
    Char(char),
    Str(String),
    Bytes(Vec<u8>),
    Num {
        data: String,
        flag: NumFlag,
    },
    Lambda,
    ColonEq,
    Underscore,
    Eq,
    At,
    Dot,
    Dot2,
    Dot3,
    Semi,
    Colon,
    Colon2,
    Comma,
    Pound,
    Bang,
    ParenL,
    ParenR,
    BrackL,
    BrackR,
    CurlyL,
    CurlyR,
    Pipe,
    ArrowR,
    ArrowL,
    FatArrow,
    Tilde,
    Invalid {
        data: String,
        msg: String,
        pos: Location,
    },
    Eof,
}

impl Token {
    /// Utility method for matching on `Token`'s of the `Operator` variant.
    pub fn as_operator(&self) -> Option<Operator> {
        if let Token::Operator(op) = self {
            Some(op.clone())
        } else {
            None
        }
    }
    /// Since symbols are interned, in order to get their `&str`
    /// representation we need an interner `Lexicon` for
    /// `Lower`, `Upper`, and  `Operator` (= `Operator::Custom`) variants.
    ///
    /// Variants `Kw`, `Operator::Reserved` (under `Token::Operator`)
    /// are not necessarily dependent on their interned representations
    /// as they are dynamically generated by macros.
    pub fn display(&self, lexicon: &Lexicon) -> String {
        match self {
            Token::Lower(s)
            | Token::Upper(s)
            | Token::Operator(Operator::Custom(s)) => {
                lexicon[*s].into()
            }
            _ => {
                format!("{}", self)
            }
        }
    }

    pub fn get_symbol(&self) -> Option<Symbol> {
        match self {
            Token::Lower(s)
            | Token::Upper(s)
            | Token::Operator(Operator::Custom(s)) => {
                Some(*s)
            }
            _ => None,
        }
    }

    /// Utility method to extract the inner comment of a `Token::Comment` variant as an `Option` type.
    /// Returns None if `Token` is not a `Comment` variant.
    pub fn as_comment(self) -> Option<Comment> {
        if let Token::Comment(comment) = self {
            Some(comment)
        } else {
            None
        }
    }

    pub fn is_terminal(&self) -> bool {
        matches!(
            self,
            Token::Lower(..)
                | Token::Upper(..)
                | Token::Num { .. }
                | Token::Char(..)
                | Token::Str(..)
                | Token::Bytes(..)
                | Token::Operator(..)
                | Token::Kw(..)
                | Token::Lambda
                | Token::ParenL
                | Token::BrackL
        )
    }

    pub fn as_u8(&self) -> Result<u8, TokenError> {
        if let Token::Num {
            data,
            flag: NumFlag::Int,
        } = self
        {
            u8::from_str_radix(data.as_str(), 10)
                .map_err(|err| TokenError::ParseInt(err))
        } else {
            Err(TokenError::Incompatible(format!("Unable to read `{}` as u8! Token must be a `Num` variant with an `Int` flag.", self)))
        }
    }

    pub fn as_assoc_spec(
        &self,
    ) -> Result<Assoc, TokenError> {
        match self {
            Token::Kw(Keyword::InfixL) => Ok(Assoc::Left),
            Token::Kw(Keyword::InfixR) => Ok(Assoc::Right),
            t => Err(TokenError::Incompatible(format!("The token `{}` cannot be coerced into an Assoc variant!", t)))
        }
    }

    /// Utility method used to match the referenced [`Token`] value
    /// contained by the [`Option<&Token>`] emitted when calling
    /// `peek()` on some parent with type `P` satisfying the trait bounds
    ///   
    ///     P: Peek<Peeked = Token>
    ///
    /// In other words, given an `Option<&Token>` and a slice of `Token`s,
    /// returns true or false if inner `&Token` matches any elements of the
    /// given slice.
    pub fn is_one_of(
        peeked: Option<&Token>,
        candidates: &[Token],
    ) -> bool {
        if let Some(t) = peeked {
            candidates.contains(&t)
        } else {
            false
        }
    }

    /// Tokens which mark the beginning of an expression
    pub fn begins_expr(&self) -> bool {
        match self {
            // keywords with expression production rules
            Token::Kw(
                Keyword::If
                | Keyword::Case
                | Keyword::Let
                | Keyword::Do,
            )
            // operator sections, such as `+5` -- include or exclude?
            | Token::Operator(_)
            // literals
            | Token::Lower(_)
            | Token::Upper(_)
            | Token::Char(_)
            | Token::Str(_)
            | Token::Bytes(_)
            | Token::Num { .. }
            // lambda expression
            | Token::Lambda
            | Token::ParenL
            // not including wildcard, as it is only a pattern!
            // | Token::Underscore
            // | Token::Bang
            | Token::BrackL => true,
            _ => false,
        }
    }

    /// Utility method to identify whether a token begins a pattern.
    /// The actual production rule used after invoking this method is
    /// responsible for ensuring the validity of a given pattern with
    /// respect to context -- which is not covered by this method.
    ///
    /// **NOTE:** The term `pattern` refers to the *general category*
    /// of nodes formed by tokens that may not necessarily be evaluated.
    /// Patterns are used in the following *contexts*:
    ///
    /// * lambda arguments
    /// * let bindings
    /// * case expression match arms (their lhs)
    /// * function declarations
    /// * type literals and annotations
    ///
    /// Not all of the above scenarios use the same set of patterns.
    /// For example, a pattern containing any sort of literal data
    /// (i.e., `Str`, `Char`, `Num`, `Bytes`) is valid for *case* expressions
    /// and *function* declarations, while not allowed in *lambda* arguments.
    ///
    pub fn begins_pat(&self) -> bool {
        match self {
            Token::Upper(_)
            | Token::Lower(_)
            | Token::Char(_)
            | Token::Str(_)
            | Token::Bytes(_)
            | Token::Underscore
            | Token::Dot2
            | Token::Num { .. }
            | Token::BrackL
            | Token::ParenL => true,
            _ => false,
        }
    }
}

impl std::convert::TryFrom<Token> for Assoc {
    type Error = TokenError;
    fn try_from(value: Token) -> Result<Self, Self::Error> {
        value.as_assoc_spec()
    }
}

#[derive(Clone, Debug)]
pub enum TokenError {
    ParseInt(std::num::ParseIntError),
    ParseFloat(std::num::ParseFloatError),
    Incompatible(String),
}

impl std::fmt::Display for TokenError {
    fn fmt(
        &self,
        f: &mut std::fmt::Formatter<'_>,
    ) -> std::fmt::Result {
        fn g(
            f: &mut std::fmt::Formatter<'_>,
            e: impl std::fmt::Display,
        ) -> std::fmt::Result {
            write!(f, "Token error: {}", e)
        }

        match self {
            TokenError::ParseInt(e) => g(f, e),
            TokenError::ParseFloat(e) => g(f, e),
            TokenError::Incompatible(e) => g(f, e),
        }
    }
}

impl From<std::num::ParseIntError> for TokenError {
    fn from(err: std::num::ParseIntError) -> Self {
        Self::ParseInt(err)
    }
}

impl From<std::num::ParseFloatError> for TokenError {
    fn from(err: std::num::ParseFloatError) -> Self {
        Self::ParseFloat(err)
    }
}

impl From<&str> for TokenError {
    fn from(err: &str) -> Self {
        Self::Incompatible(err.into())
    }
}

impl std::convert::TryFrom<Token> for u8 {
    type Error = TokenError;

    fn try_from(value: Token) -> Result<Self, Self::Error> {
        value.as_u8()
    }
}

impl From<BinOp> for Token {
    fn from(op: BinOp) -> Self {
        Token::Operator(Operator::Reserved(op))
    }
}

impl From<Keyword> for Token {
    fn from(kw: Keyword) -> Self {
        Token::Kw(kw)
    }
}

impl Default for Token {
    fn default() -> Self {
        Token::Eof
    }
}

impl std::fmt::Display for Token {
    fn fmt(
        &self,
        f: &mut std::fmt::Formatter<'_>,
    ) -> std::fmt::Result {
        match self {
            Token::Kw(kw) => write!(f, "{}", kw.as_str()),
            Token::Comment(c) => write!(f, "{:?}", c),
            Token::Operator(Operator::Reserved(o)) => {
                write!(f, "{}", o)
            }
            Token::Operator(Operator::Custom(s))
            | Token::Lower(s)
            | Token::Upper(s) => write!(f, "{}", s),
            Token::Str(s) => {
                write!(f, "{}", s)
            }
            Token::Char(c) => write!(f, "{}", c),
            Token::Num { data, .. } => {
                write!(f, "{}", data)
            }
            Token::Bytes(bytes) => write!(
                f,
                "{}",
                bytes
                    .iter()
                    .map(|b| *b as char)
                    .collect::<String>()
            ),
            Token::Lambda => write!(f, "\\"),
            Token::Eq => write!(f, "="),
            Token::Underscore => write!(f, "_"),
            Token::ColonEq => write!(f, ":="),
            Token::At => write!(f, "@"),
            Token::Dot => write!(f, "."),
            Token::Dot2 => write!(f, ".."),
            Token::Dot3 => write!(f, "..."),
            Token::Semi => write!(f, ";"),
            Token::Colon => write!(f, ":"),
            Token::Colon2 => write!(f, "::"),
            Token::Comma => write!(f, ","),
            Token::Pound => write!(f, "#"),
            Token::Bang => write!(f, "!"),
            Token::ParenL => write!(f, "("),
            Token::ParenR => write!(f, ")"),
            Token::BrackL => write!(f, "["),
            Token::BrackR => write!(f, "]"),
            Token::CurlyL => write!(f, "{}", '{'),
            Token::CurlyR => write!(f, "{}", '}'),
            Token::Pipe => write!(f, "|"),
            Token::ArrowR => write!(f, "->"),
            Token::ArrowL => write!(f, "<-"),
            Token::FatArrow => write!(f, "=>"),
            Token::Tilde => write!(f, "~"),
            Token::Invalid {
                data: val,
                msg,
                pos,
            } => write!(
                f,
                "Invalid: `{}`: {} at {}",
                val, msg, pos
            ),
            Token::Eof => write!(f, "\0"),
        }
    }
}
